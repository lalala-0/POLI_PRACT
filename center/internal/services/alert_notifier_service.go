package services

import (
	"bytes"
	"center/internal/config"
	"center/internal/models"
	"context"
	"encoding/json"
	"fmt"
	"log"
	"net/http"
	"net/smtp"
	"strconv"
	"strings"
	"sync"
	"time"
)

type checkResult struct {
	success int
	fail    int
}

type AlertNotifierService struct {
	cfg           config.AlertsConfig // –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–∑ YAML
	hostService   *HostService
	checksCounter *checkResult
	alertRules    map[int][]models.AlertRule // –ö—ç—à –ø—Ä–∞–≤–∏–ª –∞–ª–µ—Ä—Ç–æ–≤
	logMu         sync.Mutex
	ruleMu        sync.RWMutex
}

// –ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä
func NewAlertNotifierService(cfg config.AlertsConfig, hostService *HostService) *AlertNotifierService {
	checksCounter := &checkResult{0, 0}
	service := &AlertNotifierService{
		cfg:           cfg,
		hostService:   hostService,
		checksCounter: checksCounter,
		alertRules:    make(map[int][]models.AlertRule),
	}
	service.refreshAlertRules(context.Background())
	// –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–∞–≤–∏–ª –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
	//go service.loadAlertRules(context.Background())
	return service
}

// loadAlertRules –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç –æ–±–Ω–æ–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ
func (s *AlertNotifierService) loadAlertRules(ctx context.Context) {
	ticker := time.NewTicker(5 * time.Minute)
	defer ticker.Stop()

	for {
		s.refreshAlertRules(ctx)
		select {
		case <-ctx.Done():
			return
		case <-ticker.C:
			s.refreshAlertRules(ctx)
		}
	}
}

func (s *AlertNotifierService) refreshAlertRules(ctx context.Context) {
	hosts, err := s.hostService.GetAllHosts(ctx)
	if err != nil {
		log.Printf("Failed to load hosts for alert rules: %v", err)
		return
	}

	newRules := make(map[int][]models.AlertRule)
	for _, host := range hosts {
		rules, err := s.hostService.GetAlertsByHostID(ctx, host.ID)
		if err != nil {
			log.Printf("Failed to get alerts for host %d: %v", host.ID, err)
			continue
		}
		newRules[host.ID] = rules
	}

	s.ruleMu.Lock()
	s.alertRules = newRules
	s.ruleMu.Unlock()
}

// InvalidateAlertRules –æ–±–Ω–æ–≤–ª—è–µ—Ç –∞–ª–µ—Ä—Ç—ã –≤ –∫—ç—à–µ
func (s *AlertNotifierService) InvalidateAlertRules() {
	s.ruleMu.Lock()
	defer s.ruleMu.Unlock()

	// –û—á–∏—â–∞–µ–º –∫—ç—à, —á—Ç–æ–±—ã –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∑–∞–≥—Ä—É–∑–∏–ª–∏—Å—å —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ
	s.alertRules = make(map[int][]models.AlertRule)

	// –ò–Ω–∏—Ü–∏–∏—Ä—É–µ–º –Ω–µ–º–µ–¥–ª–µ–Ω–Ω—É—é –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫—É
	go s.refreshAlertRules(context.Background())
}

// CheckHostAlerts –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–∞–≤–∏–ª–∞–º –∞–ª–µ—Ä—Ç–æ–≤
func (s *AlertNotifierService) CheckHostAlerts(ctx context.Context, host *models.Host, metrics *models.Metrics) {
	s.ruleMu.RLock()
	rules, ok := s.alertRules[host.ID]
	s.ruleMu.RUnlock()

	//log.Println("------------1-------------------", host.ID, ":   ", rules)
	if !ok {
		return
	}

	//log.Println("------------2-------------------")
	host, err := s.hostService.GetHost(ctx, host.ID)
	if err != nil {
		log.Printf("Failed to get host for alert: %v", err)
		return
	}

	//log.Println("------------3-------------------")
	for _, rule := range rules {
		if !rule.Enabled {
			continue
		}

		triggered, current := s.evaluateRule(metrics, rule)
		if !triggered {
			continue
		}
		message := fmt.Sprintf("üîî ALERT: Host %s (%s): %s %s %.2f (current: %s)",
			host.Hostname, host.IPAddress, rule.MetricName, rule.Condition, rule.ThresholdValue, current)
		log.Println(message)
		s.sendAlert(message)
	}
}

func (s *AlertNotifierService) evaluateRule(metrics *models.Metrics, rule models.AlertRule) (bool, string) {
	// –ü–∞—Ä—Å–∏–º –∏–º—è –º–µ—Ç—Ä–∏–∫–∏: —Ç–∏–ø.–∏–º—è.–ø–æ–ª–µ
	parts := strings.Split(rule.MetricName, ".")
	l := len(parts)
	if l < 2 || l > 3 {
		return false, "invalid metric name"
	}

	metricType := parts[0]
	var objectName, fieldName string
	if l == 2 {
		fieldName = parts[1]
	} else {
		objectName = parts[1]
		fieldName = parts[2]
	}

	switch metricType {
	case "system":
		return s.evaluateSystemMetric(metrics.SystemMetrics, rule, fieldName)
	case "process":
		return s.evaluateProcessMetric(metrics.ProcessesInfo, rule, objectName, fieldName)
	case "container":
		return s.evaluateContainerMetric(metrics.ContainersInfo, rule, objectName, fieldName)
	case "network":
		return s.evaluateNetworkMetric(metrics.PortsInfo, rule, objectName, fieldName)
	default:
		return false, "unknown metric type"
	}
}

func (s *AlertNotifierService) evaluateSystemMetric(system models.SystemDetails, rule models.AlertRule, fieldName string) (bool, string) {
	var value float64
	var current string

	switch fieldName {
	case "cpu_usage_percent":
		value = system.CPU.UsagePercent
		current = fmt.Sprintf("%.2f%%", value)
	case "memory_usage_percent":
		value = system.RAM.UsagePercent
		current = fmt.Sprintf("%.2f%%", value)
	case "disk_usage_percent":
		value = system.Disk.UsagePercent
		current = fmt.Sprintf("%.2f%%", value)
	default:
		return false, "unknown system metric"
	}

	return s.compare(value, rule), current
}

func (s *AlertNotifierService) evaluateProcessMetric(processes []models.ProcessInfo, rule models.AlertRule, processName, fieldName string) (bool, string) {
	for _, proc := range processes {
		if proc.Name == processName {
			var value float64
			var current string

			switch fieldName {
			case "cpu_percent":
				value = proc.CPUPercent
				current = fmt.Sprintf("%.2f%%", value)
			case "memory_mb":
				value = proc.MemoryMB
				current = fmt.Sprintf("%.2fMB", value)
			default:
				return false, "unknown process metric"
			}

			return s.compare(value, rule), current
		}
	}
	return false, "process not found"
}

func (s *AlertNotifierService) evaluateContainerMetric(containers []models.ContainerInfo, rule models.AlertRule, containerName, fieldName string) (bool, string) {
	for _, cont := range containers {
		if cont.Name == containerName {
			var value float64
			var current string

			switch fieldName {
			case "cpu_percent":
				value = cont.CPUPercent
				current = fmt.Sprintf("%.2f%%", value)
			case "memory_percent":
				value = cont.MemoryPercent
				current = fmt.Sprintf("%.2f%%", value)
			case "status":
				// –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç–∞—Ç—É—Å –≤ —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
				if cont.Status == "running" {
					value = 1
				} else {
					value = 0
				}
				current = cont.Status
			default:
				return false, "unknown container metric"
			}

			return s.compare(value, rule), current
		}
	}
	return false, "container not found"
}

func (s *AlertNotifierService) evaluateNetworkMetric(ports []models.PortInfo, rule models.AlertRule, portStr, fieldName string) (bool, string) {
	port, err := strconv.Atoi(portStr)
	if err != nil {
		return false, "invalid port"
	}

	for _, p := range ports {
		if p.LocalPort == port {
			var value float64
			var current string

			switch fieldName {
			case "status":
				// –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç–∞—Ç—É—Å –≤ —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
				if p.State == "LISTEN" {
					value = 1
				} else {
					value = 0
				}
				current = p.State
			default:
				return false, "unknown network metric"
			}

			return s.compare(value, rule), current
		}
	}
	return false, "port not found"
}

func (s *AlertNotifierService) compare(value float64, rule models.AlertRule) bool {
	switch rule.Condition {
	case ">":
		return value > rule.ThresholdValue
	case "<":
		return value < rule.ThresholdValue
	case "=":
		return value == rule.ThresholdValue
	case ">=":
		return value >= rule.ThresholdValue
	case "<=":
		return value <= rule.ThresholdValue
	case "!=":
		return value != rule.ThresholdValue
	default:
		return false
	}
}

// sendAlert –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤–æ –≤—Å–µ –∫–∞–Ω–∞–ª—ã
func (s *AlertNotifierService) sendAlert(message string) {
	// –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Telegram –¥–ª—è –≤—Å–µ—Ö —á–∞—Ç–æ–≤
	for _, chatID := range s.cfg.Telegram.ChatIDs {
		if err := SendTelegramMessage(s.cfg.Telegram.Token, chatID, message); err != nil {
			log.Printf("Telegram alert to %s failed: %v", chatID, err)
		}
	}

	//// –û—Ç–ø—Ä–∞–≤–∫–∞ email –≤—Å–µ–º –ø–æ–ª—É—á–∞—Ç–µ–ª—è–º
	//if err := SendEmailAlert(s.cfg.Email, "üîî Monitoring Alert", message); err != nil {
	//	log.Printf("Email alert failed: %v", err)
	//}
}

func SendTelegramMessage(token, chatID, text string) error {
	url := "https://api.telegram.org/bot" + token + "/sendMessage"
	data := map[string]string{
		"chat_id": chatID,
		"text":    text,
	}
	body, _ := json.Marshal(data)
	_, err := http.Post(url, "application/json", bytes.NewBuffer(body))
	return err
}

// SendEmailAlert –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç email-—É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –ø–æ –∑–∞–¥–∞–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏.
func SendEmailAlert(cfg config.EmailConfig, subject, message string) error {
	// –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∏ —Ç–µ–ª–æ –ø–∏—Å—å–º–∞
	from := cfg.Username
	to := strings.Join(cfg.To, ",")
	body := fmt.Sprintf("To: %s\r\nSubject: %s\r\n\r\n%s", to, subject, message)

	auth := smtp.PlainAuth("", cfg.Username, cfg.Password, cfg.SMTPHost)
	addr := fmt.Sprintf("%s:%d", cfg.SMTPHost, cfg.SMTPPort)
	//log.Println("              auth:", auth, ", addr:", addr, ", body:", body, "to:", to)
	if err := smtp.SendMail(addr, auth, from, cfg.To, []byte(body)); err != nil {
		log.Printf("failed to send email: %w", err)
		return err
	}
	return nil
}

func (s *AlertNotifierService) recordCheckResult(success bool) {
	s.logMu.Lock()
	defer s.logMu.Unlock()
	if success {
		s.checksCounter.success++
	} else {
		s.checksCounter.fail++
	}
}

//
//// Start –∑–∞–ø—É—Å–∫–∞–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
//func (s *AlertNotifierService) Start(ctx context.Context) {
//	go s.alertMonitor(ctx)
//}

//
//// AfterPoll –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —Ü–∏–∫–ª–∞ –æ–ø—Ä–æ—Å–∞ —Ö–æ—Å—Ç–æ–≤
//func (s *AlertNotifierService) AfterPoll(results map[int]bool) {
//	for hostID, success := range results {
//		s.recordPollResult(hostID, success)
//	}
//}

func (s *AlertNotifierService) AlertMonitor(ctx context.Context) {
	ticker := time.NewTicker(time.Duration(s.cfg.IntervalSeconds) * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			return
		case <-ticker.C:
			s.checksCounterAlerts()
		}
	}
}

func (s *AlertNotifierService) checksCounterAlerts() {
	s.logMu.Lock()
	defer s.logMu.Unlock()
	failureRate := float64(s.checksCounter.fail) / float64(s.checksCounter.fail+s.checksCounter.success) * 100.
	s.checksCounter.success = 0
	s.checksCounter.fail = 0
	// –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ä–æ–≥ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è
	if failureRate >= s.cfg.FailureThresholdPercent {
		message := fmt.Sprintf("üö® ALERT Monitoring center failed: %.0f%% failures in last %d seconds",
			failureRate, s.cfg.IntervalSeconds)

		log.Println(message)

		// –æ—Ç–ø—Ä–∞–≤–∫–∞ –≤ Telegram –∏ Email
		go s.sendAlert(message)
	}
}
